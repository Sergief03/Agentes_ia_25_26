# ğŸ¤– Chatbot RAG - Sistema de Consulta de Documentos IES

Sistema de bÃºsqueda semÃ¡ntica y chatbot basado en RAG (Retrieval Augmented Generation) para consultar el Reglamento de OrganizaciÃ³n y Funcionamiento (ROF) del IES.

---

## ğŸ“– Ãndice

1. [DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)
2. [Â¿QuÃ© es RAG?](#-quÃ©-es-rag)
3. [Â¿QuÃ© es un Embedding?](#-quÃ©-es-un-embedding)
4. [Flujo de Ingesta de Datos](#-flujo-de-ingesta-de-datos)
5. [Requisitos](#-requisitos)
6. [InstalaciÃ³n](#-instalaciÃ³n)
7. [EjecuciÃ³n](#-ejecuciÃ³n)
8. [Scripts Disponibles](#-scripts-disponibles)
9. [Arquitectura y Componentes](#-arquitectura-y-componentes)
10. [Estructura de Datos](#-estructura-de-datos)
11. [Decisiones de DiseÃ±o](#-decisiones-de-diseÃ±o)
12. [Backend y Frontend](#-prÃ³ximas-fases)
13. [Estructura del Proyecto](#-estructura-del-proyecto)

---

## ğŸ¯ DescripciÃ³n del Proyecto

Este proyecto implementa un sistema RAG (Retrieval Augmented Generation) que permite realizar consultas en lenguaje natural sobre documentos extensos, especÃ­ficamente el Reglamento de OrganizaciÃ³n y Funcionamiento del instituto.

### CaracterÃ­sticas principales:

- âœ… **BÃºsqueda semÃ¡ntica**: Encuentra informaciÃ³n relevante aunque no coincidan las palabras exactas
- âœ… **Embeddings locales**: Genera vectores usando Ollama (sin dependencias de APIs externas)
- âœ… **Base de datos vectorial**: Qdrant para bÃºsquedas rÃ¡pidas y eficientes
- âœ… **EjecuciÃ³n completa**: Desde procesamiento de texto hasta bÃºsqueda semÃ¡ntica
- âœ… **Dockerizado**: FÃ¡cil despliegue con Docker Compose

---

## ğŸ§  Â¿QuÃ© es RAG?

**RAG (Retrieval Augmented Generation)** es una tÃ©cnica que combina:

1. **Retrieval (RecuperaciÃ³n)**: Busca informaciÃ³n relevante en una base de datos
2. **Augmented (Aumentada)**: Enriquece el contexto con los datos encontrados
3. **Generation (GeneraciÃ³n)**: Genera respuestas coherentes usando un LLM

### Flujo RAG

```
Usuario: "Â¿CuÃ¡l es el horario de entrada?"
           â†“
    [1. RECUPERACIÃ“N]
           â†“
    BÃºsqueda semÃ¡ntica en BD
           â†“
    Fragmentos relevantes encontrados
           â†“
    [2. AUMENTACIÃ“N]
           â†“
    Contexto + Consulta â†’ LLM
           â†“
    [3. GENERACIÃ“N]
           â†“
    "El horario de entrada es de 08:00 a 08:30..."
```

### Ventajas de RAG

- âœ… **Respuestas basadas en datos reales** 
- âœ… **Actualizaciones fÃ¡ciles** 
- âœ… **Trazabilidad** 
- âœ… **EspecÃ­fico del dominio** 

---

## ğŸ”¢ Â¿QuÃ© es un Embedding?

Un **embedding** es una representaciÃ³n vectorial (numÃ©rica) de un texto que captura su significado semÃ¡ntico.

### Concepto bÃ¡sico

```
Texto: "Â¿CuÃ¡l es el horario de entrada?"
         â†“ (Modelo de embeddings)
Vector: [0.123, -0.456, 0.789, ..., 0.321]  (768 dimensiones)
```

### Propiedades clave

1. **Textos similares â†’ Vectores cercanos**

   ```
   "horario de entrada" â‰ˆ [0.5, 0.3, 0.1, ...]
   "hora de llegada"    â‰ˆ [0.4, 0.3, 0.2, ...]
   ```

2. **BÃºsqueda por similitud**

   - Se calcula la **similitud de coseno** entre vectores
   - Valores de 0 (diferentes) a 1 (idÃ©nticos)

3. **Espacio semÃ¡ntico**
   - Palabras relacionadas estÃ¡n cerca en el espacio vectorial
   - Permite encontrar conceptos relacionados aunque usen palabras diferentes

### Ejemplo visual

```
Espacio vectorial (simplificado a 2D):

    "horario de entrada" â—
                          \
                           \ â† Alta similitud (0.87)
                            \
                   "hora de llegada" â—


    "uniforme del centro" â—  â† Baja similitud (0.32)
```

---

## ğŸ”„ Flujo de Ingesta de Datos

El proceso completo de transformar documentos en un sistema de bÃºsqueda semÃ¡ntica:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 1: PROCESAMIENTO (procesar_rof.js)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  datos/datos.txt (ROF completo)                                 â”‚
â”‚         â†“                                                       â”‚
â”‚  FragmentaciÃ³n (chunks)                                         â”‚
â”‚         â†“                                                       â”‚
â”‚  datos/chunks.json                                              â”‚
â”‚  [                                                              â”‚
â”‚    {                                                            â”‚
â”‚      "id": 1,                                                   â”‚
â”‚      "contenido": "El horario de entrada...",                   â”‚
â”‚      "fuente": "ROF IES HLanz",                                 â”‚
â”‚      "pagina": 5                                                â”‚
â”‚    },                                                           â”‚
â”‚    ...                                                          â”‚
â”‚  ]                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 2: GENERACIÃ“N DE EMBEDDINGS (generar_embedings.js)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Para cada chunk:                                               â”‚
â”‚    "El horario de entrada..." â†’ Ollama â†’ [0.1, -0.5, 0.7, ...]  â”‚
â”‚                                                                 â”‚
â”‚  datos/embeddings.json                                          â”‚
â”‚  [                                                              â”‚
â”‚    {                                                            â”‚
â”‚      "id": 1,                                                   â”‚
â”‚      "contenido": "El horario de entrada...",                   â”‚
â”‚      "embedding": [0.123, -0.456, 0.789, ...],                  â”‚
â”‚      "fuente": "ROF IES HLanz",                                 â”‚
â”‚      "pagina": 5                                                â”‚
â”‚    },                                                           â”‚
â”‚    ...                                                          â”‚
â”‚  ]                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 3: CARGA EN BASE DE DATOS (cargar_bd.js)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Qdrant (Base de datos vectorial)                               â”‚
â”‚                                                                 â”‚
â”‚  ColecciÃ³n: fragmentos_rof                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚ ID  â”‚ Vector (768D)   â”‚ Payload         â”‚                    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                    â”‚
â”‚  â”‚ 1   â”‚ [0.1, -0.5,...] â”‚ {contenido,... }â”‚                    â”‚
â”‚  â”‚ 2   â”‚ [0.3, 0.2,...]  â”‚ {contenido,... }â”‚                    â”‚
â”‚  â”‚ ... â”‚ ...             â”‚ ...             â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                                                 â”‚
â”‚  âœ… Indexado para bÃºsqueda rÃ¡pida                              â”‚
â”‚  âœ… BÃºsqueda por similitud de coseno                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BÃšSQUEDA SEMÃNTICA (test_busqueda.js)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Consulta: "Â¿CuÃ¡l es el horario de entrada?"                    â”‚
â”‚         â†“                                                       â”‚
â”‚  Embedding de consulta â†’ [0.15, -0.48, 0.72, ...]               â”‚
â”‚         â†“                                                       â”‚
â”‚  BÃºsqueda en Qdrant (similitud de coseno)                       â”‚
â”‚         â†“                                                       â”‚
â”‚  Resultados ordenados por relevancia:                           â”‚
â”‚    1. [0.87] "El horario de entrada es de 08:00..."             â”‚
â”‚    2. [0.72] "Los estudiantes deben llegar puntualmente..."     â”‚
â”‚    3. [0.65] "El retraso se justifica solamente..."             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Requisitos

### Software necesario

#### 1. **Node.js** (v18 o superior)

```bash
node --version  # Verificar versiÃ³n
```

#### 2. **Docker** y **Docker Compose**

```bash
docker --version
docker-compose --version
```

#### 3. **Servicios Docker** (incluidos en el proyecto)

- **Qdrant**: Base de datos vectorial (puerto 6333)
- **Ollama**: Servidor de modelos LLM y embeddings (puerto 11434)

### Datos

- **ROF en formato texto**: Archivo `datos/datos.txt` con el contenido del reglamento

### Modelos Ollama

El proyecto usa:

- `nomic-embed-text`: Modelo de embeddings (768 dimensiones)

---

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone <url-del-repositorio>
cd chatbot-rag-SFF-EMT-IBC
```

### 2. Instalar dependencias

```bash
npm install
```

### 3. Colocar el archivo ROF

Coloca el archivo de texto del ROF en:

```
datos/datos.txt
```

### 4. Configurar variables de entorno

Copia el archivo de ejemplo y configÃºralo:

```bash
# Windows
copy .env.example .env

# Linux/Mac
cp .env.example .env
```

Edita `.env` con tus configuraciones:

```bash
# Ollama
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL_EMBEDDINGS=nomic-embed-text
OLLAMA_MODEL_LLM=llama3.2

# Qdrant
QDRANT_URL=http://localhost:6333
QDRANT_COLLECTION_NAME=fragmentos_rof

# Entorno
NODE_ENV=development
```

### 5. Iniciar servicios Docker

```bash
docker-compose up -d
```

Verifica que los servicios estÃ©n corriendo:

```bash
docker ps
```

DeberÃ­as ver:

- `qdrant` en puerto 6333
- `ollama` en puerto 11434

### 6. Descargar modelo de embeddings

```bash
docker exec -it ollama ollama pull nomic-embed-text
```

---

## â–¶ï¸ EjecuciÃ³n

### EjecuciÃ³n completa

El comando `ingesta` ejecuta todo el proceso automÃ¡ticamente:

```bash
npm run ingesta
```

Esto ejecuta en secuencia:

1. âœ… `procesar` â†’ Fragmenta el ROF en chunks
2. âœ… `embeddings` â†’ Genera vectores para cada chunk
3. âœ… `cargar-bd` â†’ Carga los vectores en Qdrant

**Salida esperada:**

```
> Procesando ROF...
âœ… 87 fragmentos generados
âœ… Guardados en datos/chunks.json

> Generando embeddings...
Procesando 87/87...
âœ… Embeddings generados exitosamente
â± GeneraciÃ³n completada en 45.23 segundos
ğŸ“ Guardados en datos/embeddings.json

> Cargando en base de datos...
ğŸ—„ Inicializando base de datos...
âœ… Tabla 'fragmentos' creada
ğŸ“¥ Insertando 87 fragmentos...
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 87/87 100%
âœ… Base de datos cargada exitosamente
ğŸ“Š Fragmentos en BD: 87
ğŸ’¾ TamaÃ±o de archivo: 3.2 MB
âœ… Integridad verificada
```

---

## ğŸ“œ Scripts Disponibles

### Scripts de ingesta

#### 1. `npm run procesar`

**Fase 1: Trocear el ROF**

Fragmenta el documento completo en chunks manejables.

```bash
npm run procesar
```

**Entrada:** `datos/datos.txt`  
**Salida:** `datos/chunks.json`

**Funcionalidad:**

- Lee el archivo ROF completo
- Divide en fragmentos de tamaÃ±o Ã³ptimo
- AÃ±ade metadata (fuente, pÃ¡gina)
- Valida tamaÃ±o mÃ­nimo (100 caracteres)

---

#### 2. `npm run embeddings`

**Fase 2: Generar vectores**

Genera embeddings para cada fragmento usando Ollama.

```bash
npm run embeddings
```

**Entrada:** `datos/chunks.json`  
**Salida:** `datos/embeddings.json`

**Funcionalidad:**

- Lee los chunks generados
- Para cada chunk, genera embedding (768 dimensiones)
- Guarda fragmento + embedding
- Muestra progreso y tiempo estimado

---

#### 3. `npm run cargar-bd`

**Fase 3: Cargar a base de datos**

Almacena los embeddings en Qdrant.

```bash
npm run cargar-bd
```

**Entrada:** `datos/embeddings.json`  
**Salida:** ColecciÃ³n Qdrant `fragmentos_rof`

**Funcionalidad:**

- Inicializa colecciÃ³n en Qdrant
- Inserta fragmentos en lotes (optimizaciÃ³n)
- Valida duplicados
- Verifica integridad de datos

---

### Scripts de prueba

#### 4. `npm run test-busqueda`

**Probar bÃºsqueda semÃ¡ntica**

Ejecuta consultas de prueba y muestra resultados.

```bash
npm run test-busqueda
```

**Consultas de ejemplo:**

- "Â¿CuÃ¡l es el horario de entrada?"
- "Â¿QuÃ© hacer ante inasistencias?"
- "Uniforme del centro"

**Salida esperada:**

```
ğŸ” Buscando fragmentos similares a: "Â¿CuÃ¡l es el horario de entrada?"
ğŸ“ Resultados (similitud):

1. [0.87] "El horario de entrada es de 08:00 a 08:30..."
2. [0.72] "Los estudiantes deben llegar puntualmente..."
3. [0.65] "El retraso se justifica solamente en caso de..."
```

---

#### 5. `npm run dev`

**Modo desarrollo**

Ejecuta test de bÃºsqueda con recarga automÃ¡tica (Ãºtil para desarrollo).

```bash
npm run dev
```

---

## ğŸ—ï¸ Arquitectura y Componentes

El proyecto sigue una arquitectura de microservicios orquestada con Docker Compose, separando las responsabilidades para facilitar el desarrollo, despliegue y escalabilidad.

```
      Usuario
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     HTTP/JSON      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Frontend      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚      Backend     â”‚
â”‚ (HTML, CSS, JS)  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   (Node/Express) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                                                 â”‚ API Calls
                                                 â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                       Contenedores Docker                â”‚
          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
          â”‚      App (Backend) â”‚      Qdrant      â”‚      Ollama      â”‚
          â”‚  (Este contenedor) â”‚   (BD Vectorial) â”‚  (Host Machine)  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes Clave

#### 1. **Frontend (`/frontend`)**
-   **TecnologÃ­a**: HTML5, CSS3, JavaScript (Vanilla JS).
-   **FunciÃ³n**: Proporciona una interfaz de chat para que el usuario interactÃºe con el sistema. Se comunica con el backend a travÃ©s de una API REST para enviar preguntas y recibir respuestas. Es una aplicaciÃ³n de pÃ¡gina Ãºnica (SPA) servida directamente por el backend de Express.

#### 2. **Backend (`/backend`)**
-   **TecnologÃ­a**: Node.js con Express.js.
-   **FunciÃ³n**: ActÃºa como el cerebro del sistema. Orquesta todo el flujo RAG:
    1.  Recibe la consulta del usuario desde el frontend.
    2.  Llama a **Ollama** para convertir la consulta en un *embedding* (vector numÃ©rico).
    3.  Usa ese vector para buscar los fragmentos de texto mÃ¡s relevantes en la base de datos vectorial **Qdrant**.
    4.  Construye un *prompt* enriquecido con los fragmentos recuperados.
    5.  EnvÃ­a el *prompt* a **Ollama** para que un Modelo de Lenguaje Grande (LLM) genere una respuesta en lenguaje natural.
    6.  Devuelve la respuesta y las fuentes al frontend.

#### 3. **Ollama (Servicio Externo en Host)**
-   **FunciÃ³n**: Proporciona los modelos de inteligencia artificial de forma local.
-   **Modelo de Embeddings (`nomic-embed-text`)**: Transforma texto en vectores numÃ©ricos que capturan su significado.
-   **Modelo de Lenguaje (`llama3.2`)**: Genera las respuestas en texto conversacional basÃ¡ndose en el contexto proporcionado por el backend.
-   **ComunicaciÃ³n**: El backend se conecta a Ollama a travÃ©s de `host.docker.internal`, lo que permite que el contenedor de la aplicaciÃ³n acceda a un servicio que se ejecuta en la mÃ¡quina anfitriona.

#### 4. **Qdrant (Servicio Docker)**
-   **TecnologÃ­a**: Base de datos vectorial.
-   **FunciÃ³n**: Almacena los *embeddings* de todos los fragmentos del documento ROF. Permite realizar bÃºsquedas de similitud a alta velocidad para encontrar los fragmentos mÃ¡s relevantes para una consulta dada.

#### 5. **Docker Compose (`docker-compose.yml`)**
-   **FunciÃ³n**: Orquesta el despliegue de todos los servicios (`backend`/`frontend` y `qdrant`). Define las redes, volÃºmenes y variables de entorno, asegurando que todos los componentes puedan comunicarse entre sÃ­ de manera predecible.

---

## ğŸ“Š Estructura de Datos

### 1. `chunks.json`

Fragmentos del documento original.

```json
[
  {
    "id": 1,
    "contenido": "El horario de entrada es de 08:00 a 08:30. Los estudiantes...",
    "fuente": "ROF IES HLanz",
    "pagina": 5
  },
  {
    "id": 2,
    "contenido": "Las faltas de asistencia deberÃ¡n justificarse documentalmente...",
    "fuente": "ROF IES HLanz",
    "pagina": 12
  }
]
```

**Campos:**

- `id`: Identificador Ãºnico del fragmento
- `contenido`: Texto del fragmento (100-500 caracteres aprox.)
- `fuente`: Origen del documento
- `pagina`: NÃºmero de pÃ¡gina (si disponible)

---

### 2. `embeddings.json`

Fragmentos con sus vectores de embedding.

```json
[
  {
    "id": 1,
    "contenido": "El horario de entrada es de 08:00 a 08:30...",
    "embedding": [0.123, -0.456, 0.789, ..., 0.321],
    "fuente": "ROF IES HLanz",
    "pagina": 5
  }
]
```

**Campos adicionales:**

- `embedding`: Array de 768 nÃºmeros (vector semÃ¡ntico del texto)

**TamaÃ±o del vector:**

- Dimensiones: 768
- Modelo: `nomic-embed-text`
- Rango de valores: aproximadamente [-1, 1]

---

### 3. ColecciÃ³n Qdrant: `fragmentos_rof`

Estructura en la base de datos vectorial:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PUNTO (Point)                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id: 1                                               â”‚
â”‚                                                     â”‚
â”‚ vector: [0.123, -0.456, 0.789, ..., 0.321]          â”‚
â”‚         â†‘                                           â”‚
â”‚         768 dimensiones                             â”‚
â”‚                                                     â”‚
â”‚ payload: {                                          â”‚
â”‚   contenido: "El horario de entrada...",            â”‚
â”‚   fuente: "ROF IES HLanz",                          â”‚
â”‚   pagina: 5,                                        â”‚
â”‚   creado_en: "2025-11-25T10:00:00.000Z"             â”‚
â”‚ }                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ConfiguraciÃ³n de la colecciÃ³n:**

- DimensiÃ³n de vectores: 768
- MÃ©trica de distancia: Coseno (Cosine)
- IndexaciÃ³n: HNSW (Hierarchical Navigable Small World)

---

## ğŸ¨ Decisiones de DiseÃ±o

### 1. Â¿Por quÃ© Qdrant?

Aunque el enunciado menciona SQLite, se decidiÃ³ usar **Qdrant** por:

âœ… **Optimizado para bÃºsqueda vectorial**: Qdrant estÃ¡ diseÃ±ado especÃ­ficamente para bÃºsquedas de similitud


âœ… **Escalabilidad**: Qdrant puede manejar millones de vectores eficientemente


âœ… **Ãndices especializados**


âœ… **Facilidad de uso**:

- API REST simple
- CÃ¡lculo de similitud incorporado
- Docker image oficial

---

### 2. Â¿Por quÃ© nomic-embed-text?

âœ… **Optimizado para espaÃ±ol**

âœ… **TamaÃ±o razonable**


---

### 3. TamaÃ±o mÃ­nimo de fragmentos: 100 caracteres

âœ… **Contexto suficiente**

- 100 caracteres â‰ˆ 15-20 palabras (Suficiente para capturar una idea completa)

âœ… **Evita fragmentos inÃºtiles**

âœ… **Balance**

- Fragmentos muy grandes: contexto mezclado
- Fragmentos muy pequeÃ±os: sin contexto suficiente

**ConfiguraciÃ³n recomendada:**

- MÃ­nimo: 100 caracteres
- Ã“ptimo: 200-400 caracteres
- MÃ¡ximo: 500 caracteres

---

### 4. Otras decisiones

**Batch size: 50**

- Inserciones en lotes para optimizar velocidad
- Balance entre memoria y velocidad

**Distance metric: Cosine**

- Normalizado (0-1)
- No afectado por magnitud del vector
- EstÃ¡ndar en NLP

**Puerto Qdrant: 6333**

- Puerto por defecto de Qdrant
- HTTP/REST API

---

## ğŸ”Œ Backend y Frontend

### Backend (API REST con Express)

El backend, construido con Node.js y Express, expone una API REST para gestionar el flujo RAG. El punto de entrada principal es `server.js`.

#### Endpoint principal: `POST /api/chat`

Este endpoint orquesta todo el proceso de consulta y generaciÃ³n de respuesta:

1.  **Recibe la consulta**: Acepta un cuerpo JSON con la pregunta del usuario.
    ```json
    { "mensaje": "Â¿CuÃ¡l es el horario de entrada?" }
    ```

2.  **Genera el Embedding de la Consulta**: Se comunica con el servicio de **Ollama** para convertir la pregunta del usuario en un vector numÃ©rico (embedding).

3.  **BÃºsqueda en Qdrant**: Utiliza el vector para realizar una bÃºsqueda de similitud en la base de datos vectorial **Qdrant**, recuperando los fragmentos de texto mÃ¡s relevantes del documento.

4.  **GeneraciÃ³n de Respuesta con LLM**: Construye un *prompt* que incluye la pregunta original y los fragmentos recuperados. EnvÃ­a este *prompt* enriquecido a **Ollama** para que el modelo de lenguaje (`llama3.2`) genere una respuesta coherente y contextualizada.

5.  **Devuelve la Respuesta**: EnvÃ­a una respuesta JSON al frontend que contiene el texto generado y las fuentes utilizadas.
    ```json
    {
      "respuesta": "SegÃºn el reglamento, el horario de entrada es de 8:15 a 14:45 horas.",
      "fuentes": [
        { "contenido": "ArtÃ­culo 9. Horario general. El horario lectivo del centro serÃ¡ de 8:15 a 14:45 horas...", "fuente": "ROF IES HLanz" }
      ]
    }
    ```

---

### Frontend (Interfaz de Chat)

La interfaz de usuario es una aplicaciÃ³n de pÃ¡gina Ãºnica (SPA) construida con HTML, CSS y JavaScript (Vanilla JS).

#### Funcionalidades clave:

1.  **Interfaz de Chat**: El archivo `index.html` define la estructura de una ventana de chat donde el usuario puede escribir sus preguntas. Los estilos se gestionan en `styles.css`.

2.  **LÃ³gica del Cliente (`app.js`)**:
    -   Captura el mensaje enviado por el usuario.
    -   Muestra un indicador de "escribiendo..." mientras espera la respuesta del servidor.
    -   Realiza una llamada `fetch` al endpoint `/api/chat` del backend, enviando la pregunta.
    -   Al recibir la respuesta, la muestra en la interfaz de chat, junto con las fuentes de informaciÃ³n que el LLM utilizÃ³ para generarla.

3.  **Servido por Express**: El propio backend de Express se encarga de servir los archivos estÃ¡ticos del frontend, simplificando el despliegue.

---

## ğŸ“ Estructura del Proyecto
```
chatbot-rag-SFF-EMT-IBC/
â”œâ”€â”€ ğŸ“ backend/                                   # API y procesamiento RAG + BD
â”‚   â”œâ”€â”€ server.js                                 # Servidor Express + endpoints
â”‚   â”œâ”€â”€ routes/                                   # Controladores de la API
â”‚   â”œâ”€â”€ ğŸ“ datos/                                 # Datos generados y fuente
â”‚   â”‚   â”œâ”€â”€ PLAN-DE-CENTRO-SIMPLE.txt             # ROF en texto plano (fuente principal)
â”‚   â”‚   â”œâ”€â”€ chunks.json                           # Fragmentos del ROF
â”‚   â”‚   â””â”€â”€ embeddings.json                       # Embeddings del ROF
â”‚   â”œâ”€â”€ ğŸ“ node_modules/                          # Dependencias node (NO en Git)
â”‚   â”œâ”€â”€ ğŸ“ scripts/                               # Scripts del pipeline RAG (ETL)
â”‚   â”‚   â”œâ”€â”€ procesar_rof.js                       # Fase 1: DivisiÃ³n en chunks
â”‚   â”‚   â”œâ”€â”€ generar_embeddings.js                 # Fase 2: Crear embeddings Qdrant
â”‚   â”‚   â”œâ”€â”€ cargar_bd.js                          # Fase 3: Carga a la BD vectorial
â”‚   â”‚   â””â”€â”€ test_busqueda.js                      # Validar la similitud en Qdrant
â”‚   â”œâ”€â”€ .env                                      # Variables privadas del backend (omitido en Git)
â”‚   â”œâ”€â”€ Dockerfile                                # Imagen Docker para backend
â”‚   â”œâ”€â”€ package-lock.json
â”‚   â”œâ”€â”€ package.json                              # Scripts NPM y dependencias backend
â”‚   â””â”€â”€ validacion.http                           # Pruebas manuales API REST
â”‚
â”‚
â”œâ”€â”€ ğŸ“ docs/                                      # DocumentaciÃ³n del proyecto
â”‚   â”œâ”€â”€ cargar_bd_README.md                       # GuÃ­a fase de carga en BD
â”‚   â”œâ”€â”€ checklist.md                              # Lista de tareas del proyecto
â”‚   â”œâ”€â”€ FRONTEND_CHAT.md                          # DiseÃ±o UI del chatbot
â”‚   â”œâ”€â”€ IMPEMENTACION_COMPLETA.md                 # DocumentaciÃ³n del flujo completo
â”‚   â”œâ”€â”€ README.md                                 # DocumentaciÃ³n general
â”‚   â”œâ”€â”€ RESUMEN_FINAL.md                          # Informe final presentado
â”‚   â””â”€â”€ test_busqueda_README.md                   # ExplicaciÃ³n del script de prueba
â”‚
â”œâ”€â”€ ğŸ“ frontend/                                  # Interfaz del Chatbot
â”‚   â”œâ”€â”€ app.js                                    # LÃ³gica del cliente y llamadas API
â”‚   â”œâ”€â”€ Dockerfile                                # Imagen Docker para frontend
â”‚   â”œâ”€â”€ favicon.svg
â”‚   â”œâ”€â”€ index.html                                # Interfaz del chatbot
â”‚   â”œâ”€â”€ package-lock.json
â”‚   â”œâ”€â”€ package.json                              # Scripts NPM y dependencias frontend
â”‚   â””â”€â”€ styles.css                                # Estilos del chatbot
â”‚
â”œâ”€â”€ ğŸ“ public/                                  
â”‚   â””â”€â”€ ğŸ“ img/                                    
â”‚        â”œâ”€â”€ Chat_interface.jpg                                
â”‚        â””â”€â”€ demo_animaciÃ³n.mp4
â”‚
â”œâ”€â”€ ğŸ“„ .env.example                                # Ejemplo de variables de entorno
â”œâ”€â”€ ğŸ“„ .gitignore                                 # Archivos ignorados por Git
â”œâ”€â”€ ğŸ“„ docker-compose.yml                         # OrquestaciÃ³n de servicios Docker
â”œâ”€â”€ ğŸ“„ README_DOCKER.md                           # GuÃ­a de despliegue con Docker
â””â”€â”€ ğŸ“„ README.md                                  # DescripciÃ³n principal del proyecto
```
---

## ğŸ› ï¸ Comandos Ãºtiles

### Docker

```bash
# Iniciar servicios
docker-compose up -d

# Ver logs
docker logs qdrant
docker logs ollama

# Detener servicios
docker-compose down

# Reiniciar servicios
docker-compose restart
```

### Qdrant

```bash
# Ver colecciones
curl http://localhost:6333/collections

# Ver info de colecciÃ³n
curl http://localhost:6333/collections/fragmentos_rof

# Contar puntos
curl http://localhost:6333/collections/fragmentos_rof/points/count
```

### Ollama

```bash
# Listar modelos descargados
docker exec -it ollama ollama list

# Descargar modelo
docker exec -it ollama ollama pull nomic-embed-text

# Probar embedding
curl http://localhost:11434/api/embeddings -d '{
  "model": "nomic-embed-text",
  "prompt": "test"
}'
```

---

## ğŸ“š Recursos adicionales

### DocumentaciÃ³n oficial

- [Qdrant Documentation](https://qdrant.tech/documentation/)
- [Ollama Documentation](https://github.com/ollama/ollama/blob/main/docs/api.md)
- [Nomic Embed Text](https://www.nomic.ai/blog/posts/nomic-embed-text-v1)

### Conceptos

- [RAG explained](https://www.pinecone.io/learn/retrieval-augmented-generation/)
- [Embeddings explained](https://platform.openai.com/docs/guides/embeddings)
- [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)

### Tutoriales

- [Building a RAG system](https://www.youtube.com/watch?v=sVcwVQRHIc8)
- [Vector databases explained](https://www.youtube.com/watch?v=klTvEwg3oJ4)

---

###  ğŸ‘¥ Colaboradores

Este proyecto se ha sido realizado por:
 
- Sergio FernÃ¡ndez FernÃ¡ndez 
- IvÃ¡n Balderas Carmona
- Esther Maroto Torres

El trabajo se ha repertido por apartados especificado en el archivo `checkList.md`
