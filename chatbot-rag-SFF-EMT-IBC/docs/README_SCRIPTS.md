# üìú Gu√≠a de Scripts del Pipeline RAG

Este documento ofrece una explicaci√≥n detallada de cada uno de los scripts que componen el pipeline de ingesta y prueba del sistema RAG. Estos scripts se encargan de procesar el documento fuente, generar los embeddings y cargarlos en la base de datos vectorial para su posterior consulta.

---

## ‚ñ∂Ô∏è Ejecuci√≥n Completa del Pipeline

Para ejecutar todo el proceso de ingesta de datos de forma secuencial y automatizada, puedes usar el siguiente comando:

```bash
npm run ingesta
```

Este comando ejecuta los siguientes scripts en orden:

1.  `npm run procesar`
2.  `npm run embeddings`
3.  `npm run cargar-bd`

---

## üìÑ Fase 1: `scripts/procesar_rof.js`

Este script es el primer paso del pipeline. Su funci√≥n es leer el documento de texto plano (`.txt`) y dividirlo en fragmentos m√°s peque√±os y manejables, conocidos como _chunks_.

### Ejecuci√≥n

```bash
npm run procesar
```

### Funcionalidad Detallada

- **Entrada**: `backend/datos/PLAN-DE-CENTRO-SIMPLE.txt`.
- **Salida**: `backend/datos/chunks.json`.
- **Proceso**:
  1.  Lee el contenido completo del archivo de texto.
  2.  Divide el texto en p√°rrafos, utilizando el doble salto de l√≠nea (`\n\n`) como separador.
  3.  Filtra y descarta los fragmentos que no alcanzan un umbral m√≠nimo de 100 caracteres para asegurar que contengan informaci√≥n relevante.
  4.  Asigna a cada fragmento un `id` √∫nico, el `contenido` del texto, una `fuente` (nombre del documento) y un n√∫mero de `pagina` (actualmente un valor fijo).
  5.  Guarda el array de objetos resultante en formato JSON.

### Estructura de Salida (`chunks.json`)

```json
[
  {
    "id": 1,
    "contenido": "El horario general del centro ser√° de 8:15 horas a 21:45 horas de forma ininterrumpida...",
    "fuente": "ROF IES HLanz",
    "pagina": 1
  },
  ...
]
```

---

## üî¢ Fase 2: `scripts/generar_embeddings.js`

Una vez que el texto est√° fragmentado, este script se encarga de convertir cada _chunk_ de texto en una representaci√≥n num√©rica (vector) llamada _embedding_.

### Ejecuci√≥n

```bash
npm run embeddings
```

### Funcionalidad Detallada

- **Entrada**: `backend/datos/chunks.json`.
- **Salida**: `backend/datos/embeddings.json`.
- **Proceso**:
  1.  Lee el archivo `chunks.json` generado en la fase anterior.
  2.  Para cada fragmento de texto, realiza una llamada a la API de **Ollama** (`/api/embeddings`).
  3.  Utiliza el modelo `nomic-embed-text` para generar un vector de 768 dimensiones que captura el significado sem√°ntico del texto.
  4.  Muestra una barra de progreso en la consola para visualizar el avance y el tiempo estimado.
  5.  Guarda un nuevo archivo JSON que contiene los datos del fragmento original junto con su `embedding` correspondiente.

### Estructura de Salida (`embeddings.json`)

```json
[
  {
    "id": 1,
    "contenido": "El horario general del centro ser√° de 8:15 horas a 21:45 horas...",
    "embedding": [0.123, -0.456, 0.789, ...],
    "fuente": "ROF IES HLanz",
    "pagina": 1
  },
  ...
]
```

---

## üíæ Fase 3: `scripts/cargar_bd.js`

Este script toma los fragmentos y sus embeddings y los almacena en **Qdrant**, una base de datos vectorial optimizada para b√∫squedas de similitud.

### Ejecuci√≥n

```bash
npm run cargar-bd
```

### Funcionalidad Detallada

- **Entrada**: `backend/datos/embeddings.json`.
- **Salida**: Una colecci√≥n poblada en la base de datos Qdrant (ej. `fragmentos_rof`).
- **Proceso**:
  1.  **Inicializaci√≥n**: Se conecta a Qdrant y, para asegurar una carga limpia, elimina la colecci√≥n si ya existe y la crea de nuevo. La dimensi√≥n de los vectores (768) y la m√©trica de distancia (`Cosine`) se configuran en este paso.
  2.  **Inserci√≥n en lotes (Batching)**: Lee el archivo `embeddings.json` e inserta los datos en Qdrant en lotes de 50 para optimizar el rendimiento y evitar sobrecargar la API.
  3.  **Uso de `upsert`**: Este comando inserta nuevos puntos o actualiza los existentes si el `id` ya existe, manejando la consistencia de los datos.
  4.  **Verificaci√≥n**: Al finalizar, el script verifica que la carga se ha completado correctamente, contando el n√∫mero de puntos en la colecci√≥n y mostrando el tama√±o del archivo procesado.

### Salida en Consola

```
üóÑ Inicializando base de datos...
‚úÖ Colecci√≥n 'fragmentos_rof' creada.
üì• Insertando 87 fragmentos...
[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 87/87 100%
‚úÖ Base de datos cargada exitosamente.
üìä Fragmentos en BD: 87
üíæ Tama√±o de archivo: 3.2 MB
‚úÖ Integridad verificada.
```

---

## üîç Script de Prueba: `scripts/test_busqueda.js`

Este script es una herramienta de validaci√≥n que permite probar la eficacia de la b√∫squeda sem√°ntica directamente desde la consola, sin necesidad de un backend o frontend completos.

### Ejecuci√≥n

```bash
npm run test-busqueda
```

### Funcionalidad Detallada

- **Proceso**:
  1.  Define una lista de consultas de prueba (ej: "¬øCu√°l es el horario de entrada?").
  2.  Para cada consulta, primero genera su _embedding_ llamando a **Ollama**.
  3.  Utiliza este _embedding_ para realizar una b√∫squeda de similitud en **Qdrant**. Qdrant compara el vector de la consulta con todos los vectores almacenados y devuelve los m√°s cercanos (los m√°s relevantes sem√°nticamente).
  4.  Muestra en la consola los 3 fragmentos m√°s relevantes para cada consulta, junto con su puntuaci√≥n de similitud (score).

### ¬øC√≥mo funciona la b√∫squeda sem√°ntica?

1.  **Generaci√≥n de embedding de consulta**:
    ```
    "¬øCu√°l es el horario de entrada?" ‚Üí (Ollama) ‚Üí [0.12, -0.45, ..., 0.78]
    ```
2.  **B√∫squeda vectorial en Qdrant**: Qdrant utiliza la **similitud de coseno** para medir el "√°ngulo" entre el vector de la consulta y los vectores de los fragmentos almacenados. Un √°ngulo m√°s peque√±o (un score m√°s cercano a 1.0) significa una mayor similitud sem√°ntica.

3.  **Resultados ordenados**: Devuelve los fragmentos con el score m√°s alto.

### Interpretaci√≥n de los Scores

- **0.90 - 1.00**: Coincidencia sem√°ntica casi perfecta.
- **0.70 - 0.89**: Alta relevancia. El fragmento est√° muy relacionado con la consulta.
- **0.50 - 0.69**: Relevancia moderada. El fragmento toca el tema de la consulta.
- **< 0.50**: Baja relevancia.

### Salida en Consola

```
üîç Buscando fragmentos similares a: "¬øQu√© hacer ante inasistencias?"
üìç Resultados (similitud):

1. [0.65] "a las clases y actividades programadas. Las faltas de asistencia deber√°n just..."
2. [0.62] "horas, de lunes a viernes. Las actividades extraescolares podr√°n desarrollars..."
3. [0.59] "a cooperaci√≥n y la no violencia. Se rechaza toda forma de acoso, discriminaci..."
```

---

## ‚öôÔ∏è Scripts de Desarrollo

### `npm run dev`

Este comando ejecuta el script `test_busqueda.js` en modo de vigilancia (`watch`). Es √∫til durante el desarrollo, ya que vuelve a ejecutar las pruebas de b√∫squeda autom√°ticamente cada vez que se guarda un cambio en el archivo.

```bash
npm run dev
```

---

## üìÅ Estructura de Archivos Relevante

```
chatbot-rag-SFF-EMT-IBC/
‚îî‚îÄ‚îÄ backend/
    ‚îú‚îÄ‚îÄ datos/
    ‚îÇ   ‚îú‚îÄ‚îÄ PLAN-DE-CENTRO-SIMPLE.txt  # Entrada
    ‚îÇ   ‚îú‚îÄ‚îÄ chunks.json                # Salida de 'procesar'
    ‚îÇ   ‚îî‚îÄ‚îÄ embeddings.json            # Salida de 'embeddings'
    ‚îî‚îÄ‚îÄ scripts/
        ‚îú‚îÄ‚îÄ procesar_rof.js
        ‚îú‚îÄ‚îÄ generar_embeddings.js
        ‚îú‚îÄ‚îÄ cargar_bd.js
        ‚îî‚îÄ‚îÄ test_busqueda.js
```

## üõ†Ô∏è Configuraci√≥n

Todos los scripts leen su configuraci√≥n del archivo `.env` en la ra√≠z del proyecto. Aseg√∫rate de que las siguientes variables est√©n correctamente definidas:

```env
# Ollama
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL_EMBEDDINGS=nomic-embed-text

# Qdrant
QDRANT_URL=http://localhost:6333
QDRANT_COLLECTION_NAME=fragmentos_rof
```

## üêõ Soluci√≥n de Problemas Comunes

#### Error: "No existe datos/embeddings.json"

**Causa**: No se ha ejecutado el script `generar_embeddings.js` antes de `cargar_bd.js`.
**Soluci√≥n**: Ejecuta `npm run embeddings` o el pipeline completo `npm run ingesta`.

#### Error de conexi√≥n con Qdrant u Ollama

**Causa**: Los contenedores de Docker no est√°n en ejecuci√≥n.
**Soluci√≥n**:

1.  Verifica que los servicios est√©n activos con `docker ps`.
2.  Si no lo est√°n, in√≠cialos con `docker-compose up -d`.
3.  Aseg√∫rate de que las URLs en el archivo `.env` coinciden con los puertos expuestos en `docker-compose.yml`.

#### Scores de similitud muy bajos

**Causa**:

- La consulta no est√° relacionada con el contenido del documento.
- El modelo de embeddings utilizado para la b√∫squeda es diferente al utilizado durante la ingesta.
- La fragmentaci√≥n del texto no es √≥ptima y ha perdido contexto.
  **Soluci√≥n**:

1.  Aseg√∫rate de que `OLLAMA_MODEL_EMBEDDINGS` es el mismo en todas las fases.
2.  Revisa los fragmentos en `chunks.json` para ver si tienen sentido de forma aislada.
3.  Prueba con consultas m√°s espec√≠ficas o reformuladas.
